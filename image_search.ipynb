{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Install and import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import openai  \n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import math\n",
    "import base64\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from tenacity import retry, stop_after_attempt, wait_random_exponential\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Azure Credentials\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "# Azure Cognitive Search imports\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import VectorFilterMode, RawVectorQuery\n",
    "from azure.search.documents.indexes.models import (  \n",
    "    SearchFieldDataType,\n",
    "    SimpleField,\n",
    "    SearchableField,\n",
    "    SearchField,\n",
    "    VectorSearch,\n",
    "    HnswVectorSearchAlgorithmConfiguration,\n",
    "    VectorSearchAlgorithmKind,\n",
    "    HnswParameters,\n",
    "    ExhaustiveKnnVectorSearchAlgorithmConfiguration,\n",
    "    ExhaustiveKnnParameters,\n",
    "    VectorSearchProfile,\n",
    "    SearchIndex\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Central variables image search:\n",
    "if not load_dotenv('./mydotenv.env'): raise Exception(\".env file not found\")\n",
    "\n",
    "# Azure OpenAI\n",
    "api_base = '<your_azure_openai_endpoint>' \n",
    "deployment_name = '<your_deployment_name>'\n",
    "API_KEY = '<your_azure_openai_key>'\n",
    "\n",
    "base_url = f\"{api_base}openai/deployments/{deployment_name}\" \n",
    "\n",
    "\n",
    "\n",
    "# Azure Computer Vision\n",
    "key = os.getenv(\"AZURE_CV_KEY\")\n",
    "endpoint = os.getenv(\"AZURE_CV_ENDPOINT\")\n",
    "\n",
    "\n",
    "\n",
    "# Azure Cognitive Search\n",
    "cs_key = os.getenv(\"COG_SEARCH_ADMIN_KEY\")\n",
    "cs_endpoint = os.getenv(\"COG_SEARCH_ENDPOINT\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "headers = {   \n",
    "    \"Content-Type\": \"application/json\",   \n",
    "    \"api-key\": API_KEY \n",
    "} \n",
    "\n",
    "\n",
    "# Function to get the Image description for the input image using GPT4-vision Chat Completion API\n",
    "def get_image_description(image_path,prompt):\n",
    "      \n",
    "    base64_image = encode_image(image_path=image_path)\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"gpt-4-vision-preview\",\n",
    "        \"messages\": [\n",
    "          {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "              {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": f\"{prompt}?\"\n",
    "              },\n",
    "              {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                  \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                },\n",
    "              }\n",
    "            ]\n",
    "          }\n",
    "        ],\n",
    "        \"max_tokens\": 1000\n",
    "    }\n",
    "\n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "\n",
    "    temp = response.json()\n",
    "    return temp['choices'][0]['message']['content']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Function to generate embeddings for title and content fields, also used for query embeddings\n",
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
    "def get_text_embeddings(text):\n",
    "    response = openai.Embedding.create(\n",
    "        input=text, engine=\"text-embedding-ada-002\")\n",
    "    embeddings = response['data'][0]['embedding']\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def show_images(images, cols=2, source='url', savedir='', show_title=False, titles=None):\n",
    "    \"\"\"\n",
    "    Get images from URL and display them in a grid. Optionally save or retrieve images to/from local dir. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    images : list\n",
    "        List of image urls or local file paths.\n",
    "    cols : int\n",
    "        Number of columns in the grid.\n",
    "    source : str\n",
    "        'url' or 'local'\n",
    "    savedir : str\n",
    "        Directory to save images to.\n",
    "    show_title : bool\n",
    "        Display filename as image title (local files only)\n",
    "    \"\"\"\n",
    "    \n",
    "    if savedir != '':\n",
    "        os.makedirs(savedir, exist_ok=True)\n",
    "        \n",
    "    rows = int(math.ceil(len(images) / cols))\n",
    "\n",
    "    fig = plt.figure(figsize=(cols * 5, rows * 5)) # specifying the overall grid size. TODO: 7,5 for landscape images\n",
    "\n",
    "    for i, image_url in enumerate(images):\n",
    "        plt.subplot(rows, cols,i+1)  \n",
    "        \n",
    "        if source == 'url':\n",
    "            response = requests.get(image_url)\n",
    "            img = Image.open(BytesIO(response.content))\n",
    "            \n",
    "            # save images if savedir is specified\n",
    "            if savedir != '':\n",
    "                \n",
    "                # get list of png files\n",
    "                png_filenames = [image for image in os.listdir(savedir) if image.endswith('.png')]\n",
    "                # get highest index from existing files\n",
    "                if png_filenames == []:\n",
    "                    max_index = 0\n",
    "                else:\n",
    "                    max_index = max([int(filename.strip('.png')) for filename in png_filenames])\n",
    "\n",
    "                # save new file with index + 1\n",
    "                new_filename = f'{max_index+1:03d}.png'\n",
    "                fp = os.path.join(savedir, new_filename)\n",
    "                img.save(fp, 'PNG')            \n",
    "            \n",
    "        else: \n",
    "            img = Image.open(image_url) # local file\n",
    "            if show_title:\n",
    "                if titles is None: plt.title(image_url)\n",
    "                else: plt.title(titles[i])\n",
    "\n",
    "\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize DataFrame\n",
    "df = pd.DataFrame(columns=['Image_file', 'Image_description', 'description_embeddings'])\n",
    "\n",
    "\n",
    "# Specify the directory where images are stored\n",
    "image_root = './images - Copy'\n",
    "\n",
    "if not os.path.exists(image_root):\n",
    "    raise FileNotFoundError(f\"Directory '{image_root}' not found\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Adjust the delay time\n",
    "delay_between_requests = 2  # seconds\n",
    "\n",
    "\n",
    "# Iterate through image files in the 'images' directory\n",
    "idx = 0\n",
    "for file in os.listdir(image_root):\n",
    "    if file.endswith('.png') or file.endswith('.jpg'):\n",
    "        full_path = os.path.join(image_root, file)\n",
    "\n",
    "        # Fetch Image_description for the image\n",
    "        prompt = \"Describe this image to me in detail\"\n",
    "        image_description = get_image_description(imagefile=full_path, prompt=prompt)\n",
    "\n",
    "        # Fetch embeddings for the image descriptions\n",
    "        embedding = get_text_embeddings(image_description)\n",
    "\n",
    "        # Check if Image description is obtained successfully before proceeding\n",
    "        if image_description and embedding is not None:\n",
    "            row = [full_path, image_description, embedding]\n",
    "            df.loc[idx] = row\n",
    "            idx += 1\n",
    "        time.sleep(delay_between_requests)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Display top 6 records and one random image\n",
    "display(df.head(6))\n",
    "sample = df.sample(1)\n",
    "show_images(images=[sample.file.values[0]], source='local')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Transform the DataFrame and create a dictionary of data content\n",
    "df[\"id\"] = df.index.astype(str)\n",
    "df.columns = ['Image_file', 'Image_description', 'description_embeddings', 'id']\n",
    "docs = df.to_dict('records')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Create the Azure Cognitive search with DataFrame content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure credentials\n",
    "credential = AzureKeyCredential(cs_key)\n",
    "\n",
    "\n",
    "# Index name\n",
    "index_name = \"img_search\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create a search index\n",
    "index_client = SearchIndexClient(endpoint=cs_endpoint, credential=credential)\n",
    "\n",
    "fields = [\n",
    "    SimpleField    (name = \"id\"       , type = SearchFieldDataType.String, key=True, sortable=True, filterable=True, facetable=True),\n",
    "    SearchableField(name = \"Image_file\"    , type = SearchFieldDataType.String),\n",
    "    SearchableField(name = \"Image_description\"    , type = SearchFieldDataType.String),\n",
    "    SearchField    (name = \"description_embeddings\", type = SearchFieldDataType.Collection(SearchFieldDataType.Single),searchable=True, vector_search_dimensions=1024, vector_search_profile=\"myHnswProfile\"),\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# Configure the vector search configuration  \n",
    "vector_search = VectorSearch(\n",
    "    algorithms=[\n",
    "        HnswVectorSearchAlgorithmConfiguration(\n",
    "            name=\"myHnsw\",\n",
    "            kind=VectorSearchAlgorithmKind.HNSW,\n",
    "            parameters=HnswParameters(\n",
    "                m=4,\n",
    "                ef_construction=400,\n",
    "                ef_search=500,\n",
    "                metric= \"cosine\"\n",
    "            )\n",
    "        ),\n",
    "        ExhaustiveKnnVectorSearchAlgorithmConfiguration(\n",
    "            name=\"myExhaustiveKnn\",\n",
    "            kind=VectorSearchAlgorithmKind.EXHAUSTIVE_KNN,\n",
    "            parameters=ExhaustiveKnnParameters(\n",
    "                metric= \"cosine\"\n",
    "            )\n",
    "        )\n",
    "    ],\n",
    "    profiles=[\n",
    "        VectorSearchProfile(\n",
    "            name=\"myHnswProfile\",\n",
    "            algorithm=\"myHnsw\"\n",
    "        ),\n",
    "        VectorSearchProfile(\n",
    "            name=\"myExhaustiveKnnProfile\",\n",
    "            algorithm=\"myExhaustiveKnn\"\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create the search index with the semantic settings\n",
    "index = SearchIndex(name = index_name, fields=fields, vector_search=vector_search)\n",
    "result = index_client.create_or_update_index(index)\n",
    "print(f' {result.name} created')\n",
    "\n",
    "\n",
    "\n",
    "# Populate the index\n",
    "search_client = SearchClient(endpoint = cs_endpoint, index_name=index_name, credential=credential)\n",
    "result = search_client.upload_documents(docs)\n",
    "print(f\"Uploaded {len(docs)} documents\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Search Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How to set Desired Speed?\"\n",
    "  \n",
    "search_client = SearchClient(cs_endpoint, index_name, credential=credential)  \n",
    "\n",
    "vector_query = RawVectorQuery(vector=get_text_embeddings(query), k=5, fields=\"description_embeddings\")\n",
    "\n",
    "results = search_client.search(  \n",
    "    search_text = None,  \n",
    "    vector_filter_mode=VectorFilterMode.PRE_FILTER,\n",
    "    vector_queries = [vector_query],\n",
    "    select=['Image_file', 'Image_description'],\n",
    "    top=5\n",
    ")  \n",
    "\n",
    "\n",
    "\n",
    "img_paths = []  \n",
    "for result in results:  \n",
    "    print(f\"Title: {result['Image_file']}\")  \n",
    "    print(f\"Score: {result['@search.score']}\")  \n",
    "    img_paths.append(result['Image_file'])\n",
    "\n",
    "\n",
    "show_images(images=img_paths, cols=5, source='local')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
